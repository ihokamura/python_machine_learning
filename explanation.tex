\documentclass[uplatex]{jsarticle}
\usepackage{amsmath, amssymb, amsthm, bm}

\theoremstyle{definition}
\newtheorem{definition}{定義}[section]
\newtheorem{algorithm}[definition]{アルゴリズム}
\newtheorem{corollary}[definition]{系}
\newtheorem{lemma}[definition]{補題}
\newtheorem{proposition}[definition]{命題}
\newtheorem{theorem}[definition]{定理}

\numberwithin{equation}{section}

\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left|\left|#1\right|\right|}
\newcommand{\relmiddle}[1]{\mathrel{}\middle#1\mathrel{}}

\renewcommand{\d}{\mathrm{d}}
\renewcommand{\L}{\mathcal{L}}
\renewcommand{\proofname}{\bf{証明}}
\renewcommand{\labelenumi}{(\theenumi)}

\begin{document}
\section{分類問題ー単純な機械学習アルゴリズムのトレーニング}
与えられた入力をクラス$1$(陽性クラス)とクラス$-1$(陰性クラス)に分類する二値分類タスクを考える.
トレーニングデータとして, 入力値$\bm{x}^{(i)} \in \R^{m}$と対応するクラス$y^{(i)} \in \{-1, 1\}$ $(i = 1, \dots, n)$が与えられているとする.
決定関数$\phi$は総入力$z$, すなわち, 入力値$\bm{x}$と対応する重み$\bm{w}$の線型結合
\begin{equation}
    z = \bm{w}^{T}\bm{x} = \sum_{j = 1}^{m} w_{j}x_{j}
\end{equation}
を引数として受け取る.

\subsection{パーセプトロン}
パーセプトロンでは, サンプル$\bm{x}^{(i)}$に対する総入力が
指定された閾値$\theta$より大きい場合はクラス1を予測し, 
そうでない場合はクラス$-1$を予測する.
つまり, 決定関数$\phi$として階段関数
\begin{equation}
    \phi(z) = 
    \begin{cases}
        1  & (z \geq \theta) \\
        -1 & (z < \theta)
    \end{cases}    
\end{equation}
を採用する.
ここで, 数式を単純にするため, 閾値$\theta$を右辺に移動し, 
添字$0$の入力を$x_{0} = 1$, 重みを$w_{0} = -\theta$と定義する.
このとき, 総入力と決定関数はそれぞれ
\begin{equation}
    z = \bm{w}^{T}\bm{x} = \sum_{j = 0}^{m} w_{j}x_{j}
\end{equation}
\begin{equation}
    \phi(z) = 
    \begin{cases}
        1  & (z \geq 0) \\
        -1 & (z < 0)
    \end{cases}    
\end{equation}
と表される.
機械学習の分野では, 負の重み$w_{0} = -\theta$をバイアスユニットと呼ぶ.
パーセプトロンの学習アルゴリズムは以下の通りである.
\begin{algorithm}
    (パーセプトロン)
    \begin{enumerate}
        \item
        重み$w_{j}$を$0$または小さい乱数で初期化する.
        \item
        各トレーニングサンプル$\bm{x}^{(i)}$に対して以下を実行する.
            \begin{enumerate}
                \item
                出力値$\hat{y}^{(i)}$を
                \begin{equation}
                    \hat{y}^{(i)} = \phi(\bm{w}^{T}\bm{x}^{(i)})
                \end{equation}
                により計算する.
                \item
                重み$w_{j}$を
                \begin{equation}
                    \begin{cases}
                        w_{j} \leftarrow w_{j} + \Delta w_{j} \\
                        \Delta w_{j} = \eta(y^{(i)} - \hat{y}^{(i)})x^{(i)}_{j}
                    \end{cases}
                \end{equation}
                により更新する.
                ただし, $0 < \eta \leq 1$は学習率である.
            \end{enumerate}
    \end{enumerate}
\end{algorithm}
パーセプトロンの収束が保証されるのは, 2つのクラスが線形分離可能で, 学習率が十分に小さい場合に限られる.
2つのクラスが線形分離可能でない場合, データセットに対するトレーニングの最大回数(エポック)や誤分類の最大数を設定する必要がある.

\subsection{ADALINE}
ADALINE(ADAptive LInear NEuron)では, 重みの更新において階段関数ではなく線型関数を利用する.
すなわち, 線型関数$\phi$を用いてコスト関数$J$を
\begin{equation}
    J(\bm{w}) = \frac{1}{2}\sum_{i = 1}^{n}(y^{(i)} - \phi(\bm{w}^{T}\bm{x}^{(i)}))^{2}
\end{equation}
で定義し, これを最小化する重み$\bm{w}$を探索する.
その後, 最終的な予測はパーセプトロンと同様に階段関数で決定される.
重みの更新は勾配降下法に基づいて行われる.
\begin{algorithm}
    (ADALINE)
    \begin{enumerate}
        \item
        重み$\bm{w}$を小さい乱数で初期化する.
        \item
        重み$\bm{w}$を
        \begin{equation}
            \begin{cases}
                \bm{w} \leftarrow \bm{w} + \Delta\bm{w} \\
                \Delta\bm{w} = -\eta\nabla J(\bm{w})
            \end{cases}
        \end{equation}
        により更新する.
        ただし, $0 < \eta \leq 1$は学習率である.
    \end{enumerate}
\end{algorithm}
線型活性化関数を$\phi(z) = az$とすると, 重みの更新式は
\begin{equation}
    \Delta w_{j} = a\eta\sum_{i = 1}^{n} (y^{(i)} - \phi(\bm{w}^{T}\bm{x}^{(i)}))x^{(i)}_{j}
\end{equation}
で与えられる. 

このように, トレーニングデータの全サンプルに基づいて行われる勾配降下法をバッチ勾配降下法と呼ぶ.
重みが早く収束するような学習率$\eta$を見つけるには, 一般にはある程度の実験が必要である.
\begin{itemize}
    \item
    学習率が大きすぎると, エポックごとにコスト関数が増大していく可能性がある.
    \item
    学習率が小さすぎると, 重みが収束するまでのエポック数が大きくなる可能性がある.
\end{itemize}

勾配降下法の収束が早めるためには, 特徴量をスケーリングすることが有効である.
特に, トレーニングデータを標準化するとコスト関数の条件数が1に近づくため, エポック数を抑えることができる.

トレーニングデータが大規模になると, それら全体から重みを更新するバッチ勾配降下法は計算コストが高い.
この場合, トレーニングサンプルごとに重みを更新するオンライン勾配降下法(確率的勾配降下法)が有効である.
\begin{algorithm}
    (オンライン勾配降下法)
    \begin{enumerate}
        \item
        重み$\bm{w}$を小さい乱数で初期化する.
        \item
        各トレーニングサンプル$\bm{x}^{(i)}$に対して, 重み$\bm{w}$を
        \begin{equation}
            \begin{cases}
                \bm{w} \leftarrow \bm{w} + \Delta\bm{w} \\
                \Delta\bm{w} = a\eta(y^{(i)} - \phi(\bm{w}^{T}\bm{x}^{(i)}))\bm{x}^{(i)}
            \end{cases}
        \end{equation}
        により更新する.
        ただし, $0 < \eta \leq 1$は学習率である.
    \end{enumerate}
\end{algorithm}
バッチ勾配降下法とは異なり, オンライン勾配降下法では総入力$z$を計算するときの重み$\bm{w}$がトレーニングサンプルごとに変化することに注意する.


\section{分類問題ー機械学習ライブラリscikit-learnの活用}
\subsection{ロジスティック回帰}
与えられた入力をクラス$1$(陽性クラス)とクラス$0$(陰性クラス)に分類する二値分類タスクを考える.
トレーニングデータとして, 入力値$\bm{x}^{(i)} \in \R^{m}$と対応するクラス$y^{(i)} \in \{-1, 1\}$ $(i = 1, \dots, n)$が与えられているとする.

ロジスティック回帰では, 総入力にシグモイド関数を適用した値をその入力がクラス$1$に所属する確率と考える.
すなわち, 決定関数$\phi$を
\begin{equation}
    \phi(z) = \frac{1}{1 + \exp(-z)}
\end{equation}
で定義し, 
\begin{equation}
    P(y = 1|\bm{x}, \bm{w}) = \phi(\bm{w}^{T}\bm{x})
\end{equation}
と解釈する.
特に, 分類のみに関心がある場合は, 予測値を
\begin{equation}
    \hat{y} = 
    \begin{cases}
        1 & (\phi(\bm{w}^{T}\bm{x}) \geq 0.5) \\
        0 & (\phi(\bm{w}^{T}\bm{x}) < 0.5)
    \end{cases}
\end{equation}
とする.
重み$\bm{w}$はトレーニングデータが正しく分類される確率の最尤推定として求められる.
すなわち, 尤度
\begin{equation}
    \begin{cases}
        L(\bm{w}) = \prod_{i = 1}^{n} \phi(z^{(i)})^{y^{(i)}}(1 - \phi(z^{(i)}))^{1 - y^{(i)}} \\
        z^{(i)} = \bm{w}^{T}\bm{x}^{(i)}
    \end{cases}
\end{equation}
を最大化する重み$\bm{w}$を探索する.
ただし, 理論・実装の面から対数尤度を最小化する方が簡単であり, 通常はコスト関数
\begin{equation}
    J(\bm{w}) = -\log L(\bm{w}) = -\sum_{i = 1}^{n} \left[y^{(i)}\log \phi(z^{(i)}) + (1 - y^{(i)})\log(1 - \phi(z^{(i)}))\right]
\end{equation}
を最小化する重み$\bm{w}$を探索する.
\begin{align}
    \frac{\partial \phi}{\partial w_{j}}(z)
    &= -\frac{\exp(-z)}{(1 + \exp(-z))^{2}}x_{j} \\
    &= -(1 - \phi(z))\phi(z)x_{j}
\end{align}
に注意すると, 
\begin{align}
    \frac{\partial J}{\partial w_{j}}(\bm{w})
    &= \sum_{i = 1}^{n} \left[y^{(i)}(1 - \phi(z^{(i)})) - (1 - y^{(i)})\phi(z^{(i)})\right]x^{(i)}_{j} \\
    &= \sum_{i = 1}^{n} (y^{(i)} - \phi(z^{(i)}))x^{(i)}_{j}
\end{align}
となるので, ロジスティック回帰における重みの更新規則はADALINEと同じ形式になる.
ロジスティック回帰は線型分離可能な分類問題に対して高い性能を発揮する.

過学習(モデルの汎化性能が低下する現象)を避けるため, コスト関数を正則化することがある.
すなわち, 極端な重みにペナルティを課すことでモデルの複雑さを緩和する.
例えば, $L^{2}$正則化では, 元のコスト関数に正則化項を追加した
\begin{equation}
    \tilde{J}(\bm{w}) = J(\bm{w}) + \frac{1}{2}\lambda\sum_{j = 1}^{m} w_{j}^{2}
\end{equation}
を新たなコスト関数とする\footnote{正則化項にバイアスユニット$w_{0}$を含めることもある.}.
ここで, $\lambda$は正則化パラメータであり, 正則化の強さを制御する.
なお, 後述するSVMの慣例に従い, scikit-learnの実装では逆正則化パラメータ
\begin{equation}
    C = \frac{1}{\lambda}
\end{equation}
を制御している.

\subsection{1対他の手法}
二値分類のアルゴリズムは多値分類のアルゴリズムに拡張することができる.
すなわち, 各クラスについて自身とそれ以外のクラスに分類する二値分類器を構築し, それらの分類器のうち最大の確率を返すクラスラベルを予測値とすればよい.
このような手法を1対他(OvR)の手法と呼ぶ.

具体例として, ロジスティック回帰にOvRを適用してみる.
いま, 与えられた入力を$k$個のクラス$1, \dots, k$に分類する多値分類タスクを考える.
各クラスを自身とそれ以外に分類する関数を
\begin{equation}
    r_{\nu}(y) = 
    \begin{cases}
        1 & (y = \nu) \\
        -1 & (y \neq \nu)
    \end{cases}
    (\nu = 1, \dots, k)
\end{equation}
で定義する.
各$\nu$について$\bm{x}^{(i)}$を入力値, $r_{\nu}(y^{(i)})$を出力値とするロジスティック回帰を実行し,
そこで得られた重みを$\bm{w}_{\nu}$とする.
OvRでは, 最終的な分類器の予測値を
\begin{equation}
    \hat{y} = \arg \max_{\alpha} \phi(\bm{w}_{\alpha}^{T}\bm{x})
\end{equation}
とする.


\section{データ前処理ーよりよいトレーニングセットの構築}
\subsection{欠測データへの対処}
欠測データへの対処法としては以下のようなものが考えられる.
\begin{itemize}
    \item
    欠測値を持つサンプル・特徴量を取り除く.
    例えば, pandasのDataFrameオブジェクトのdropnaメソッドにより実装される.
    \item
    欠測値を補完する.
    例えば、scikit-learnのSimpleImputerオブジェクトのtransformメソッドにより実装される\footnote{
        scikit-learnの主要なオブジェクトは以下に分類される.
        \begin{itemize}
            \item
            推定器:データから学習するfitメソッドを実装している.
            \item
            予測器:予測を実行するpredictメソッドを実装している.
            \item
            変換器:データを変換するtransformメソッドを実装している.
        \end{itemize}
    }.
\end{itemize}

\subsection{カテゴリデータの処理}
カテゴリデータは名義特徴量と順序特徴量に分類される.
順序特徴量とは, 順序付け可能なカテゴリ値である.
例えば, Tシャツのサイズは順序特徴量である.
名義特徴量とは, 順序付け可能でないカテゴリ値である.
例えば, Tシャツの色は名義特徴量である.

通常, 機械学習のモデルを適用するためにはカテゴリデータを整数値に変換する必要がある.
ここで, 名義特徴量を整数値に変換するにあたり, 名義特徴量の各カテゴリ値を整数値に変換することは不適切である.
なぜなら, この変換により本来は存在しない順序関係が発生するからである.
この問題に対処するため, one-hotエンコーディングという手法が用いられる.
これは, 名義特徴量の各カテゴリ値に対してダミー特徴量を導入するというものである.
すなわち, $k$種類のカテゴリ$c_{1}, \dots, c_{k}$がある場合, カテゴリ$c_{i}$を$\R^{k}$の$i$番目の標準基底$\bm{e}_{i}$に変換する.

one-hotエンコーディングを使用する場合, 多重共線性の問題が発生する可能性がある.
つまり, 特徴量の相関性が高い場合, 逆行列の計算が数値的に不安定になる恐れがある.
この問題を解決するためには, 特徴量の列を一つ削除すればよい.
特徴量の列を一つ削除しても元の情報が失われないことに注意する.

\subsection{データセットをトレーニングデータセットとテストデータセットに分割する}
データセットの分割にはトレードオフを伴う.
すなわち, トレーニングデータセットを大きくすると, 学習モデルはデータセットからより多くの情報を得られるが, 汎化誤差の推定値が正確でなくなる.
慣習的には, トレーニングデータセットとテストデータセットの比率を$6:4$, $7:3$, $8:2$にすることが多い.
ただし, データセットが十分大きい場合には$9:1$や$99:1$という比率にすることもある.

\subsection{特徴量の尺度を揃える}
多くの最適化アルゴリズムは, 複数の特徴量の尺度が同じである場合にうまく動作する.
特徴量のスケーリング手法としては正規化と標準化が一般的である.
正規化とは特徴量を区間$[0, 1]$の範囲にスケーリングし直すことである.
これは, min-maxスケーリング
\begin{equation}
    x_{\text{norm}}^{(i)} = \frac{x^{(i)} - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}}
\end{equation}
において$x_{\text{min}} = 0$, $x_{\text{max}} = 1$としたものである.
一方, 標準化とは特徴量の平均が$0$, 分散が$1$となるようにスケーリングし直すことである.
すなわち, 
\begin{align}
    x_{\text{std}}^{(i)} &= \frac{x^{(i)} - \mu_{\bm{x}}}{\sigma_{\bm{x}}} \\
    \mu_{\bm{x}} &= \frac{1}{n}\sum_{i = 1}^{n} x^{(i)} \\
    \sigma_{\bm{x}}^{2} &= \frac{1}{n}\sum_{i = 1}^{n} (x^{(i)} - \mu_{\bm{x}})^{2}
\end{align}
という変換である.
標準化には外れ値に対する情報が失われないという特徴がある.
\end{document}
